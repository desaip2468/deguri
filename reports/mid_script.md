### 인사말
안녕하세요. 저희 조의 팀명은 데구리라고 합니다. 데구리는 데이터 굴삭기의 줄임말이고 데이터 마이닝이라는 용어를 많이 듣던 중에 마이너인 광부에서 더 나아가 강력한 기계인 굴삭기처럼 되고 싶다는 생각을 가지고 작명하였습니다. 포켓몬스터에 나오는 이 친구의 이름도 데구리라고 하니 연상하여 저희 팀을 기억해주시면 좋을듯 합니다.

### 맡은 역할
먼저 저희 팀원과 각 팀원이 중간발표까지 맡았던 역할은 다음과 같습니다.
박진식: 데이터 정제 및 변환, application 코드 작성, hosting 서버 설정
서아름: 문제정의, 시장자료조사
윤정하: 문제정의, 시장자료조사
한도윤: 문제정의, 분석방법조사
중간발표까지 크게 문제를 설정하는 작업과 데이터분석기반을 구축하는 일을 하였고,
중간발표이후로는 현재까지 다져놓은 기반위에서 본격적인 분석을 진행하고 결과물을 창출하는데 힘을 쏟을 계획입니다.
그럼 프로젝트 소개를 시작하겠습니다.

### 프로젝트 주제
저희 팀의 이번 프로젝트 주제는 오공육공 세대의 간편 결제 이용률 증가를 위한 방안 제안입니다. 

### 문제 제기
혹시 청중분들의 부모님들께서는 스마트폰의 여러가지 기능들을 잘 알고 자유자재로 사용하고 계신가요? 저희 부모님의 경우 오십대이신데 꽤 오랜 기간동안 스마트폰을 쓰셨음에도 불구하고 아직 여러 스마트폰의 기본적인 기능들을 숙지하지 못하셔서 저에게 물어보곤 하십니다. 그런데 계속해서 새로운 앱과 기능들이 빠른 속도로 추가되기까지 하니 저희 부모님세대는 디지털시대의 약자라고 할 수 있겠습니다. 이는 디지털 금융시장에도 해당되는 사항입니다. 
최근 각종 첨단 기술을 접목한 금융 산업이 화두로 떠오르면서 간편 결제 시장은 빠른 속도로 성장하고 있습니다. 그러나 간편 결제 이용자는 대부분 이십삼십대의 젊은층에 한정되어 있고 모바일 환경에 익숙하지 않은 중,노년층은 간편 결제 시장에서 소외되고 있습니다. 위 자료를 보시면 이공삼공 세대에 비해 사십대 이상의 중, 노년층의 간편결제 이용률이 현저하게 떨어짐을 알 수 있습니다.
이 결과 대부분의 간편결제기업들은 서비스와 혜택들을 주 사용자인 젊은 세대를 공략하는데 집중하고, 중,노년층은 고려대상에서 제외하고 있는 상황입니다.
그러나 저희 팀은 오공육공 세대가 간편 결제 시장의 블루 오션으로서, 간편 결제 업체들이 반드시 공략해야 할 타겟 소비자층이라고 봅니다. 최근의 오공육공 세대는 모바일 어플을 통해 경조사를 챙기거나 더치페이를 활용하는 등 모바일, 온라인을 이용한 금융 서비스에 점차 익숙해지고 있습니다. 또한 이들은 안정적인 경제력을 바탕으로 간편 결제 시장의 ‘큰 손’이 될 가능성이 높은 세대입니다. 과거의 베이비붐 세대로서 우리나라에서 차지하는 인구 비율 역시 매우 높습니다. 따라서 오공육공 세대는 이공삼공 세대 못지 않은 간편결제시장의 거대한 잠재 소비자로 볼 수 있습니다.
그렇다면 오공육공 세대를 효과적으로 공략하기 위해서는 어떻게 해야 할까요? 많은 설문 조사 결과에 따르면, 금융 회사들이 제공하는 ‘경제적 혜택’이 모바일, 온라인 결제에 익숙하지 않은 오공육공 세대가 그것을 이용하게 된 가장 큰 원동력이었습니다.
따라서 최종적으로 저희 조는 오공육공 세대의 취미, 성향, 소비패턴 등을 분석하여 이들에게 최적화된 할인혜택, 서비스 등의 경제적 유인이 무엇인지 찾고 그들의 간편 결제 시장 진입을 돕고자 합니다. 또한 오공육공 세대가 간편 결제 시스템을 보다 친숙하고 쉽게 느낄 수 있도록 알맞은 광고, 홍보 전략이 무엇일지도 찾아보려 합니다.

### 활용 데이터와 분석 도구
분석에 활용하는 데이터는 뒤쪽 문에 붙여진 포스터를 보시면 알 수 있듯이, 연세대 빅데이터 경진대회에서 엠브레인 회사가 제공하는 패널데이터입니다. 엠브레인 패널들은 십대에서 육십대까지 다양한 연령 분포를 보이며, 전국 각지에 거주하고 있습니다. 제공받은 데이터는 크게 엠브레인 패널들의 설문 조사 데이터, 결제 데이터, 앱 사용 데이터입니다.
그 중에서도 저희가 활용할 수 있는, 즉 오십육십대 패널의 간편결제 사용과 관련되어 보이는 구체적인 데이터 목록들을 뽑아보았습니다. 앞으로 위의 데이터들을 서로 관련지어 다양한 방면으로 분석해나갈 계획입니다의 데이터들을 서로 관련지어 다양한 방면으로 분석해나갈 계획입니다.

### 간편결제 시장분석
본격적인 분석 시작에 앞서, 간편 결제 시장에 대해 간단하게 조사를 해보았습니다. 먼저, 현재 국내의 간편 결제 시장은 꾸준히 성장하여 2017년의 거래액이 40조에 달해 전년 대비 3배 이상 성장하였습니다. 특히 온라인 간편 결제 시장의 성장이 두드러지고 있고, 삼성페이, 네이버페이, 카카오페이 등의 상위 플레이어들이 시장을 점령하고 있는 상황입니다.
그러나 아직까지 국내에서는 간편결제에 비해 신용카드 등 기존의 결제 수단에 대한 선호도가 훨씬 높아서 간편 결제 이용자를 확보하기 위해서는 신용카드보다 뛰어난 편리성, 다양한 혜택 등을 내세울 필요가 있습니다. 
또한 각 업체 별로 결제 방식이나 지원하는 플랫폼 등이 모두 다르기 때문에 각 업체에 알맞은 마케팅 전략이 필수적입니다. 

### EDA
다음으로는 간단한 EDA를 진행해보았는데요, 먼저 엠브레인 패널들의 연령별 간편 결제 이용 비율입니다. 20-40대는 간편 결제 이용률이 60%에 달하는 것에 비해 50대부터는 이용률이 급격히 떨어짐을 알 수 있습니다. 이용 비율 뿐만 아니라 이용하는 절대적인 횟수도 5060 세대에서 적게 나타났습니다.
또한 연령별 금융 결제 이용방식을 묻는 설문에서는, 전 연령 모두 현금이나 카드 등의 기존 결제방식을 이용하는 경우가 압도적으로 많았습니다. 또한 여기서도 젊은 연령층에 비해 간편결제를 거의 이용하지 않는 5060 세대의 모습을 볼 수 있었습니다. 특히 주목하고 싶은 점은 압도적인 선호 브랜드가 있는 2030 세대와 달리 5060 세대에서는 다양한 간편 결제 사의 이용률이 고르게 나타난다는 점인데요, 즉 5060 세대에게 있어 압도적인 강세를 보이는 간편 결제 업체가 아직 존재하지 않는다고 볼 수 있습니다. 

### Software Architecture. 
우리 프로젝트의 최종 작업 산출물은, 분석 결과를 interactive 하게 볼 수 있는 shiny app 이 될 예정이다. 중간 발표 때까지 우리 조는 이 shiny app 을 띄우기 위한 제반 작업에 집중했다. 그 과정에서 간단한 shiny app 을 하나 만들게 되었는데, 오늘은 지금까지 어떠한 제반 작업이 이루어졌는지 이 app 을 중심으로 설명해 보고자 한다. 작업의 종류를 크게 세 가지로 나눠 설명하고자 한다. 
- 데이터 정제 및 변환 
- application 코드 작성 
- hosting 서버 설정 

### 데이터 정제 및 변환 
엠브레인으로부터 받은 데이터 중 우리가 사용한 것은, 월별로 130만 row 이상의 데이터가 담긴 4개월치 결제 내역 csv 파일이었다. 10만 row 가 넘어가는 파일의 경우, 일반 laptop computer 로는 데이터 분석을 하기가 힘들다. 이유는 R 또는 Excel 에서 해당 파일을 불러 들이며 엄청난 양의 메모리(RAM)를 사용하기 때문이다. 이러한 이유로 인해 데이터 시각화를 간단한 방법으로 하기가 어려웠다. (`read.csv` 함수로 읽어와서, column 별로 plot 그리기가 불가능) 
문제 정의를 하기 위해 데이터의 전체적인 모습을 파악할 필요가 있었으므로, 처음에는 csv 를 스크립트를 작성하여 line by line 으로 읽어오는 방법을 시도했다. line by line 으로 읽어오면 파일에서 한 줄씩만 메모리에 읽어오고, 사용이 끝난 이후 메모리에서 지우기 때문에, 파일의 크기와 상관 없이 데이터를 scan 하는 것이 가능하다. 하지만 하나의 column 에 대해서 시각화를 할 때마다, column 안에 있는 데이터 성질에 따라서 스크립트에 때때로 큰 수정을 가해줘야 했다. 또한 파일 하나를 scan 하는데 분 단위 시간이 걸렸고, 총 파일이 4개 있었으므로 분석 하나를 하는 데 거의 10분 가까이 소요되어 굉장히 비효율적이었다. 
이후 고려한 사항은 전체 데이터를 데이터 분석 tool 에 import 시키는 것이었다. DBMS를 사용하거나, Hadoop, elasticsearch 등 빅데이터 분석 전문 도구를 사용하는 것을 고려했었다. 하지만 빅데이터 분석 전문 도구를 사용하기 위해 준비해야 할 것이 매우 많았다. 그에 비해 우리 데이터의 규모가 그렇게 크지는 않았기 때문에 (총합 2GB 정도) DBMS를 사용하는 것이 알맞다고 판단했다. DBMS 는 mysql 을 사용하기로 결정했는데, 이유는 이후에도 언급하겠지만, 팀원 중 한 명이 이미 웹 호스팅 용으로 사용하고 있는 서버가 mysql 을 사용하고 있어서였다. 
DB 사용이 결정된 이후, 엠브레인 데이터 명세에 맞게 결제내역을 import 시킬 수 있는 table schema 를 생성하였다. 그리고 csv 파일을 line by line 으로 읽어, DB 에 import 시키는 ruby 스크립트를 생성했다. Data import 과정에서 있었던 문제점은 두 가지가 있는데, 첫 번째는 실제 데이터가 데이터 명세서에 나와 있는 것과 다른 형식인 경우가 있는 것이었다. 예를 들어 integer 자료형만 들어있다고 한 column 에 character 가 들어 있거나, nullable 하지 않은 column 에 null 값이 있는 경우가 있었다. 이 경우는 import 중 오류가 발생하면 오류 내용에 따라 적절한 대응을 하는 식으로밖에 처리할 수 없었다. 다행히 이런 오류가 많이 발생하진 않았다. 
다음은 데이터의 양 자체가 너무 많아서, import 하는 데 지나치게 오랜 시간이 걸리는 것이었다. row 가 500만 개 이상이었는데, 한 row 마다 mysql 과 연결을 맺고 쿼리를 실행하고 있었던 것이 원인이었다. 따라서 script 에서 1000 개까지 row 정보를 모은 뒤, 정보를 이어 한번에 1000 개치 insert query 를 실행하도록 하자 속도가 훨씬 나아졌다.

### application 코드 작성

데이터 정제 작업을 하고, DB import 까지 시켜뒀으므로, R 에서 DB 를 사용할 준비가 완료되었다. R 라이브러리 중 `RMariaDB` 라는 것을 이용하여, DB 와 connection 을 맺고 쿼리의 결과를 R 에서의 자료구조 (`data.frame`, `vector` 등) 로 변환하는 일을 쉽게 할 수 있었다.

우리가 실제 프로젝트 분석을 시작하기 전 만들고자 했던 app 은, EDA 과정을 간편하게 해줄 수 있는 shiny app 이었다. app 의 초기 목표는 DB 에서 필요한 정보를 가져와, column 별로 X vs Y plot 을 그려 상관관계를 알아볼 수 있도록 하는 것이었다. shiny app 이 가장 잘 하는 것이 R 의 데이터 분석 결과물을 브라우저에 보여주는 것이었으므로, 이론상으로는 단순한 아이디어였으나, 실행에 옮기면서 마주한 몇 가지 문제들이 있다.

첫 번째로는, 현재 데이터가 X versus Y plot 을 그리기에는 아직 정제되지 않은 상태였다는 문제가 있었다. 단순히 수치형 column 이 없었기 때문에 plot 을 그릴 수 없었다는 이야기는 아니다. 우리가 사용하고 있는 데이터는 log 성 데이터였기 때문에, 개별 row 의 정보 가치가 크지 않았고, 기준을 가지고 그룹화를 해야만 유의미한 정보를 볼 수 있었다. 따라서 plot 을 그리려고 한다면, X 와 Y 를 공통된 조건으로 묶을 수 있는 제 3의 기준 (예: 가맹점, 결제 시기) 을 두고, 이후 생성된 그룹별로 다시 X 와 Y를 count 또는 sum 조건으로 그룹화를 하여야 했다. 아무것도 되어있지 않은 상태에서 하기는 너무 복잡한 작업 같았기 때문에, X 컬럼 하나에 대해서 count 또는 sum 으로 그룹화하여 막대그래프를 보여주는 작업을 먼저 하는 것으로 노선을 변경하였다. 이 부분은 SQL 의 group by 문을 사용하여 간단하게 처리할 수 있었다.

하지만 이후에 또 다른 문제가 있었는데, 언급된 방식대로 grouping 을 하자 결과 그룹의 수가 너무 많아진 것이었다. 대부분의 컬럼은 한 plot 에 모두 표시될 정도로 unique 한 데이터 수가 적지 않았으며 (패널 ID, 가맹점 등), unique 한 데이터 수가 적은 컬럼은 또 너무 적어서 (성별, 연령대 등) plot 에서 유의미한 정보를 얻기가 힘들었다. 이 부분은 상위 30개 그룹만을 가져오는 복잡한 SQL 쿼리를 작성하여 해결하긴 하였으나, 근본적인 문제는 전체 데이터를 보기 쉽게 표현하기 어렵다는 것이므로 일부 데이터의 plot 을 그린 것 만으로는 해결되지 않은 상태이다. 따라서 이후에 X versus Y plot 을 그릴 수 있도록 하는 작업을 마저 진행할 예정이다.

마지막으로 큰 불편함은 아니었지만, DB 에서 데이터를 가져오는 속도가 조금 느리다는 느낌이 있었다. 이는 자주 접근하는 column 에 Database Index 를 적용함으로써 해결하였다.

### hosting 서버 설정

서버 설정 과정에 대해서 간략하게 이야기해보고자 한다. shiny app 을 간단한 과정을 통해 deploy 하여 확인할 수 있는 `shinyapps.io` 라는 서비스가 있었지만, database 를 지원하는지가 불투명했고, 가격대가 좀 비쌌기 때문에 개인 서버를 쓰기로 결정했다. github starter pack 이라고 검색해 보면 학생들에게 서버 호스팅을 무료로 지원해주는 곳 몇 군데를 찾을 수 있다.

먼저 우리의 커스텀 도메인 `shiny.pjshwa.me` 가 현재 호스팅되고 있는 서버를 찾아갈 수 있도록 DNS (도메인 네임 서버) 설정을 해주었다. 이후 서버에서 완성된 R application 을 띄워두고, `shiny.pjshwa.me` 로 오는 요청이 이 R application 으로 갈 수 있도록 하는 apache httpd 설정을 해주었다.

마지막으로 mysql 연결은 app 으로부터 생성된 지 일정 시간이 지나면 끊기도록 되어 있는데, 이 문제를 방지하기 위해 application 에서 database pool 기능을 사용해 실제로 application 에 접속이 이루어질 때마다 연결을 맺고 끊는 방식으로 변경하였다.


### 분석방법
해당 데이터를 어떤 분석방법으로 분석할 것인지 소개해드리겠습니다.
저희는 앞선 EDA에서 확인하셨던 것처럼 상대적으로 많이 저조한 고연령층의 간편결제 이용률을 문제점으로 정의하고, 이들의 이용률을 촉진시키기 위해, 연령별로 간편결제 heavy user와 light user, 미사용자의 특성차이를 살펴보기로 했기 때문에, 그에 맞는 분석방법을 찾아보았습니다. 

데이터 분석 방법에는 다음과 같이 크게 4가지의 유형이 있습니다. Regression과 Classification이 있고, Clustering 그리고 Dimensionality reduction이 있는데요. 우선 저희의 데이터 구조를 보시면, 다음과 같이 패널데이터로 구성되어 있기 때문에 Linear, Logistic, Ridge, Lasso와 같은 전통적인 Regression은 사용할 수가 없습니다. 패널데이터는 1명당 여러 행의 데이터가 기록될 수 있기 때문에 횡단면적으로나, 그리고 시계열적으로나 두 가지 차원에서 iid가정이 위반되고, 다중공선성문제가 생기기 때문입니다. 만약에 예측을 하거나, 관계를 알아보고자 한다면 Jackknife나 Panel Regression을 써야 하는데 이 방법은 학부수준에서 좀 벗어난 방법이라 생각을 했고, 데이터 전처리를 통해서 행을 축소시키는 방법도 NA비율이 너무 많아져서 사용하지 않기로 하였습니다. 따라서 이 그림을 보실 때 regression은 지워버리시고 보시면 되겠습니다. 그러면 저희의 분석목적에 맞게 데이터 분석 방법론 알고리즘을 하나씩 따라가 보도록 하겠습니다.

먼저, Payment 데이터 샘플의 크기는 520만개입니다. 따라서 충분히 Large 데이터이므로 표본의 크기에 관해서 문제가 되는 것은 없기 때문에 그대로 분석을 진행하겠습니다. 저희는 연령별로 그리고 간편결제의 사용자 그룹별로 카테고리를 나누어서 분석을 진행하는 거기 때문에, Yes에 해당하는 알고리즘을 따라서 이동하겠습니다. 그리고 저희는 Target을 따로 두지 않았기 때문에, response를 보다 잘 예측하거나 response와 predictor의 관계를 설명하기 위한 Supervised 방법이 아니라, predictor set만 있을 뿐 상응하는 response가 없는 unsupervised 방법을 사용해야 합니다. 따라서 Predictor간, 즉 유사한 동류집단 간의 관계를 파악하여 유의미한 결과를 도출하는 Clustering을 사용하기로 결정하였습니다. 

이번 군집분석에서 저희는 고연령층 간편결제 사용자(heavy user, light user)와 미사용자(non user) 간의 특성차이를 살펴보기로 했기 때문에, 카테고리의 수를 Heavy User, Light User, 미사용자 총 3개의 그룹으로 미리 Setting을 해준 셈이 됩니다. 따라서 군집분석에는 계층적 군집분석과 비계층적 군집분석 중, 비계층적 군집분석 방법이 있는데, 이를 고민할 필요 없이 **비계층적 군집분석인 K-means Clustering방법**을 사용하는 것으로 결정하였습니다.

또한 Sample의 개수가 10K이상이므로 일반적인 K Means Clustering이 아니라, large data를 clustering하기 위한 **Mini Batch K-means 방법**을 사용해야 합니다. Mini Batch K-means는 대규모 클러스터링을 위한 K-means 알고리즘의 대안으로 제안되었습니다. 이 알고리즘의 Main Idea는 모든 데이터 세트를 사용하지 않음으로써 계산 비용을 줄이는 것입니다. 즉, 미니 배치 k- 수단에서 계산 비용이 가장 많이 드는 단계는 모든 관측과는 반대로 무작위로 관찰 된 샘플에서만 수행됩니다. 이 접근법은 알고리즘이 수렴성 (즉, 데이터에 적합함)을 찾기 위해 요구되는 시간을 질적으로 작은 비용으로 상당히 감소시킬 수 있기 때문에 저희같은 빅데이터의 분석방법의 Clustering에 매우 적합한 방법이라고 판단하였습니다.

다음으로, 클러스터링 기준을 말씀드리겠습니다.
클러스터를 구성하기 위한 입력변수는 연령별 간편결제 사용자인 Heavy user, light user와 미사용자인데, 이들을 구분하는 기준은 **결제금액의 합**으로 하였습니다. 왜냐하면 단순히 간편결제 이용빈도의 많고적음보다는, 간편결제회사 입장에서 마진이 많이 남는 것이 중요하다고 생각을 하였기 때문에 이를 기준으로 삼았습니다. 그래서 고연령층 데이터들만 따로 Subset한 후, 연령별로 각각 1 번씩, 총 5번 분석을 진행하기로 하였습니다. 

그리고 K평균 방법에는 클러스터의 개수 K를 미리 지정해줌에 따라 결과값이 완전히 달라져버린다는 한계점이 있는데, 저희는 이를 보완하기 위해, 먼저 처음에는 군집을 매출액 기준으로 K=3으로 설정해보고, 이 군집이 잘 맞지 않으면, “Moderate User” 그룹을 추가하여 K=4로 설정한 후 진행하기로 하였습니다.
Heavy User, Light User, 미사용자로 구성된 클러스터의 특성을 살펴보기 위한 **설명변수로는 자주 이용하는 가맹점의 종류와 위치, 결제 빈도, 자주 이용하는 간편 결제 회사, 자주 이용하는 어플리케이션 종류 등을 놓았습니다.** 이렇게 한다면 연령별로 그리고 간편결제 사용자/미사용자 그룹별로 어떤 차이와 특성(관심사,이용 가맹점 및 제품 등등)이 있는지 발견할 수 있고, 이러한 군집별 차이를 파악함으로써 고연령층의 저조한 간편결제 이용률의 제고방안을 도출할 수 있기 때문입니다. p.s가맹점 종류, 어플리케이션 종류 등은 특성 별로 그룹화 하여 분석을 진행하기로 하였습니다. 또한 추후 논의를 통해, 향후 분석에 도움이 될 수 있는 추가적인 설명 변수를 설정하기로 하였습니다. 

 ### 기대효과
마지막으로 이번 데이터사이언스 프로젝트를 통한 기대효과를 말씀드리겠습니다.
먼저 고령화 시대의 핵심 고객인 5060 세대를 공략할 수 있는 방안을 제시할뿐만 아니라 저희는 전체적인 시장차원의 분석에서 그치지 않고, 더 나아가 간편 결제 시장 분석 결과를 바탕으로 간편 결제 회사들을 온/오프라인, 이용 방법 등에 따라 분류하고 각 회사별로 적합한 마케팅 방안 까지를 도출하여 기말 발표를 진행하도록 하겠습니다. 이를 통해 간편 결제 회사는 새로운 타겟 집단을 설정하고, 경쟁적인 간편 결제 시장에서의 활로를 모색할 수 있으며 5060 세대는 간편 결제 서비스를 통한 편리한 금융 생활을 누리는 효과를 기대할 수 있습니다. 이상으로 분석방법에 대한 발표를 마치겠습니다.

